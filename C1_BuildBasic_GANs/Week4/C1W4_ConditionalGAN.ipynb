{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Conditional GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "In this notebook, you're going to make a conditional GAN in order to generate hand-written images of digits, conditioned on the digit to be generated (the class vector). This will let you choose what digit you want to generate.\n",
    "\n",
    "You'll then do some exploration of the generated images to visualize what the noise and class vectors mean.  \n",
    "\n",
    "### Learning Objectives\n",
    "1.   Learn the technical difference between a conditional and unconditional GAN.\n",
    "2.   Understand the distinction between the class and noise vector in a conditional GAN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0) # Set for our testing purposes, please do not change!\n",
    "torch.backends.mps.is_built()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28), nrow=5, show=True):\n",
    "    image_tensor = (image_tensor+1)/2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim=10, im_chan = 1, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.gen = nn.Sequential(\n",
    "            self.make_gen_block(input_dim, hidden_dim * 4),\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim),\n",
    "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True)\n",
    "\n",
    "        )\n",
    "\n",
    "    def  make_gen_block(self, input_channels, output_channels, kernel_size = 3, stride = 2, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels ,kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace = True)\n",
    "            )\n",
    "        else: return nn.Sequential(\n",
    "            nn.ConvTranspose2d(input_channels, output_channels ,kernel_size, stride),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def unsqueeze_noise(self, noise):\n",
    "        return noise.view(len(noise), self.input_dim, 1, 1)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        x = self.unsqueeze_noise(noise)\n",
    "        return self.gen(x)\n",
    "\n",
    "def get_noise(n_sample, input_dim, device='cpu'):\n",
    "    return torch.randn(n_sample, input_dim, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, im_chan = 1, hidden_dim=16):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            self.make_disc_block(im_chan, hidden_dim),\n",
    "            self.make_disc_block(hidden_dim, hidden_dim * 2),\n",
    "            self.make_disc_block(hidden_dim * 2, 1, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_disc_block(self, input_channels , output_channels, kernel_size=4, stride=1, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels ,kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.LeakyReLU(0.2, inplace = True)\n",
    "            )\n",
    "        else: return nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels ,kernel_size, stride),\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        disc_pred = self.disc(image)\n",
    "        return disc_pred.view(len(disc_pred), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success...\n"
     ]
    }
   ],
   "source": [
    "# conditoned vector creation\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_one_hot_labels(labels, n_classes):\n",
    "    return F.one_hot(labels, n_classes)\n",
    "\n",
    "assert (\n",
    "    get_one_hot_labels(\n",
    "        labels=torch.Tensor([0, 2, 1]).long(), \n",
    "        n_classes=3).tolist() == [\n",
    "    [1, 0, 0],\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 0]\n",
    "])\n",
    "\n",
    "print('Success...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "def combine_vectors(x, y):\n",
    "    return torch.cat((x.float(), y.float()), 1)\n",
    "\n",
    "combined = combine_vectors(torch.tensor([[1, 2],[3, 4]]), torch.tensor([[5,6],[7, 8]]))\n",
    "assert torch.all(combined == torch.tensor([[1, 2, 5,6], [3, 4, 7, 8]]))\n",
    "assert (type(combined[0][0].item()) == float)\n",
    "combined = combine_vectors(torch.randn(1, 4, 5), torch.randn(1, 8, 5))\n",
    "assert tuple(combined.shape) == (1, 12, 5)\n",
    "assert tuple(combine_vectors(torch.randn(1, 10, 12).long(), torch.randn(1, 20, 12).long()).shape) == (1, 30, 12)\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_shape = (1, 28, 28)\n",
    "n_classes = 10\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "n_epochs = 200\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "# device = 'cpu'\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    MNIST('.', download=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_dimension(z_dim, mnist_shape, n_classes):\n",
    "    gen_input_dim = z_dim + n_classes\n",
    "    disc_im_chan = mnist_shape[0] + n_classes\n",
    "    return gen_input_dim, disc_im_chan\n",
    "\n",
    "def test_get_input_dimension():\n",
    "    gen_dim, disc_dim = get_input_dimension(23, (12, 23, 52), 9)\n",
    "    assert gen_dim == 32\n",
    "    assert disc_dim == 21\n",
    "test_get_input_dimension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_input_dim, disc_input_dim = get_input_dimension(z_dim, mnist_shape, n_classes)\n",
    "\n",
    "gen = Generator(input_dim = gen_input_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr= lr)\n",
    "disc = Discriminator(im_chan = disc_input_dim).to(device)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "gen = gen.apply(weights_init)\n",
    "disc = disc.apply(weights_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/469 [00:08<26:30,  3.41s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations! If you've gotten here, it's working. Please let this train until you're happy with how the generated numbers look, and then go on to the exploration!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 395/469 [00:47<00:07, 10.21it/s]"
     ]
    }
   ],
   "source": [
    "cur_step = 0\n",
    "mean_generator_loss = []\n",
    "mean_discriminator_loss = []\n",
    "\n",
    "noise_and_labels = False\n",
    "fake = False\n",
    "\n",
    "fake_image_and_labels = False\n",
    "real_image_and_labels = False\n",
    "disc_fake_pred = False\n",
    "disc_real_pred = False\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for real, labels in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "\n",
    "        real = real.to(device)\n",
    "        disc_opt.zero_grad()\n",
    "        one_hot_labels = get_one_hot_labels(labels.to(device), n_classes)\n",
    "        image_one_hot_labels = one_hot_labels[:,:,None, None]\n",
    "        image_one_hot_labels = image_one_hot_labels.repeat(1, 1, mnist_shape[1], mnist_shape[2])\n",
    "\n",
    "        fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        noise_and_labels = combine_vectors(fake_noise.to(device), one_hot_labels.to(device))\n",
    "        fake = gen(noise_and_labels)\n",
    "\n",
    "        assert len(fake) == len(real)\n",
    "        assert tuple(noise_and_labels.shape) == (cur_batch_size, fake_noise.shape[1] + one_hot_labels.shape[1])\n",
    "        assert tuple(fake.shape) == (len(real), 1, 28, 28)\n",
    "\n",
    "        fake_image_and_labels = combine_vectors(fake, image_one_hot_labels)\n",
    "        real_image_and_labels = combine_vectors(real, image_one_hot_labels)\n",
    "        disc_fake_pred = disc(fake_image_and_labels.detach())\n",
    "        disc_real_pred = disc(real_image_and_labels)\n",
    "\n",
    "        assert tuple(fake_image_and_labels.shape) == (len(real), fake.detach().shape[1] + image_one_hot_labels.shape[1], 28 ,28)\n",
    "        assert tuple(real_image_and_labels.shape) == (len(real), real.shape[1] + image_one_hot_labels.shape[1], 28 ,28)\n",
    "        # Make sure that enough predictions were made\n",
    "        assert len(disc_real_pred) == len(real)\n",
    "        # Make sure that the inputs are different\n",
    "        assert torch.any(fake_image_and_labels != real_image_and_labels)\n",
    "        # Shapes must match\n",
    "        assert tuple(fake_image_and_labels.shape) == tuple(real_image_and_labels.shape)\n",
    "        assert tuple(disc_fake_pred.shape) == tuple(disc_real_pred.shape)\n",
    "\n",
    "\n",
    "        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
    "        disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        disc_opt.step() \n",
    "\n",
    "        # Keep track of the average discriminator loss\n",
    "        mean_discriminator_loss += [disc_loss.item()]\n",
    "\n",
    "        ### Update generator ###\n",
    "        # Zero out the generator gradients\n",
    "        gen_opt.zero_grad()\n",
    "\n",
    "        fake_image_and_labels = combine_vectors(fake, image_one_hot_labels)\n",
    "        # This will error if you didn't concatenate your labels to your image correctly\n",
    "        disc_fake_pred = disc(fake_image_and_labels)\n",
    "        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        # Keep track of the generator losses\n",
    "        mean_generator_loss += [gen_loss.item()]\n",
    "        #\n",
    "\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            gen_mean = sum(mean_generator_loss[-display_step:]) / display_step\n",
    "            disc_mean = sum(mean_discriminator_loss[-display_step:]) / display_step\n",
    "            print(f\"Step {cur_step}: Generator loss: {gen_mean}, discriminator loss: {disc_mean}\")\n",
    "            show_tensor_images(fake)\n",
    "            show_tensor_images(real)\n",
    "            step_bins = 20\n",
    "            x_axis = sorted([i * step_bins for i in range(len(mean_generator_loss) // step_bins)] * step_bins)\n",
    "            num_examples = (len(mean_generator_loss) // step_bins) * step_bins\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(mean_generator_loss[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Generator Loss\"\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(mean_discriminator_loss[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Discriminator Loss\"\n",
    "            )\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        elif cur_step == 0:\n",
    "            print(\"Congratulations! If you've gotten here, it's working. Please let this train until you're happy with how the generated numbers look, and then go on to the exploration!\")\n",
    "        cur_step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing noise vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "n_interpolation = 9 # How many intermediate images you want + 2 (for the start and end image)\n",
    "\n",
    "# This time you're interpolating between the noise instead of the labels\n",
    "interpolation_label = get_one_hot_labels(torch.Tensor([5]).long(), n_classes).repeat(n_interpolation, 1).float()\n",
    "\n",
    "def interpolate_noise(first_noise, second_noise):\n",
    "    # This time you're interpolating between the noise instead of the labels\n",
    "    percent_first_noise = torch.linspace(0, 1, n_interpolation)[:, None].to(device)\n",
    "    interpolation_noise = first_noise * percent_first_noise + second_noise * (1 - percent_first_noise)\n",
    "\n",
    "    # Combine the noise and the labels again\n",
    "    noise_and_labels = combine_vectors(interpolation_noise, interpolation_label.to(device))\n",
    "    fake = gen(noise_and_labels)\n",
    "    show_tensor_images(fake, num_images=n_interpolation, nrow=int(math.sqrt(n_interpolation)), show=False)\n",
    "\n",
    "# Generate noise vectors to interpolate between\n",
    "### Change me! ###\n",
    "n_noise = 5 # Choose the number of noise examples in the grid\n",
    "plot_noises = [get_noise(1, z_dim, device=device) for i in range(n_noise)]\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i, first_plot_noise in enumerate(plot_noises):\n",
    "    for j, second_plot_noise in enumerate(plot_noises):\n",
    "        plt.subplot(n_noise, n_noise, i * n_noise + j + 1)\n",
    "        interpolate_noise(first_plot_noise, second_plot_noise)\n",
    "        plt.axis('off')\n",
    "plt.subplots_adjust(top=1, bottom=0, left=0, right=1, hspace=0.1, wspace=0)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f46918ded668a0c834e2c7829f946b45f0516a6f43996cdc6a96553b91e331ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
