{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrally Normalized Generative Adversarial Networks (SN-GAN)\n",
    "\n",
    "**Goals**\n",
    "\n",
    "In this notebook, you'll learn about and implement **spectral normalization**, a weight normalization technique to stabilize the training of the discriminator, as proposed in [Spectral Normalization for Generative Adversarial Networks](https://arxiv.org/abs/1802.05957) (Miyato et al. 2018).\n",
    "\n",
    "**Background**\n",
    "\n",
    "As its name suggests, SN-GAN normalizes the weight matrices in the discriminator by their corresponding [spectral norm](https://calculus.subwiki.org/wiki/Spectral_norm#:~:text=The%20spectral%20norm%20of%20a,where%20denotes%20the%20Euclidean%20norm.), which helps control the Lipschitz constant of the discriminator. As you have learned with WGAN, [Lipschitz continuity](https://en.wikipedia.org/wiki/Lipschitz_continuity) is important in ensuring the boundedness of the optimal discriminator. In the WGAN case, this makes it so that the underlying W-loss function for the discriminator (or more precisely, the critic) is valid.\n",
    "\n",
    "As a result, spectral normalization helps improve stability and avoid vanishing gradient problems, such as mode collapse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN with Spectral Normalization\n",
    "\n",
    "In rest of this notebook, you will walk through how to apply spectral normalization to DCGAN as an example, using your earlier DCGAN implementation. You can always add spectral normalization to your other models too.\n",
    "\n",
    "Here, you start with the same setup and helper function, as you've seen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishalmaurya/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9a1881e990>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0) # Set for our testing purposes, please do not change!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    image_tensor = (image_tensor+ 1)/2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN Generator\n",
    "\n",
    "Since spectral normalization is only applied to the matrices in the discriminator, the generator implementation is the same as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, im_chan=1, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.gen = nn.Sequential(\n",
    "            self.make_gen_block(z_dim, hidden_dim*4),\n",
    "            self.make_gen_block(hidden_dim*4, hidden_dim*2, kernel_size=4, stride=1),\n",
    "            self.make_gen_block(hidden_dim*2, hidden_dim),\n",
    "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True)\n",
    "        )\n",
    "\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else: return nn.Sequential(\n",
    "            nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def unsqueeze_noise(self, noise):\n",
    "        return noise.view(len(noise), self.z_dim, 1, 1)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        x = self.unsqueeze_noise(noise)\n",
    "        return self.gen(x)\n",
    "\n",
    "def get_noise(n_sample, z_dim, device='cpu'):\n",
    "    return torch.randn(n_sample, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# unit test for generator class\n",
    "def test_generator(num_test=100):\n",
    "    gen = Generator()\n",
    "\n",
    "    test_hidden_noise = get_noise(num_test, gen.z_dim) # (100, 10)\n",
    "    test_hidden_block = gen.make_gen_block(10, 20, 4, 1)\n",
    "    test_uns_noise = gen.unsqueeze_noise(test_hidden_noise) # (100, 10, 1, 1)\n",
    "    hidden_output = test_hidden_block(test_uns_noise) # (100, 20, 4, 4)\n",
    "\n",
    "    # Check that it works with other strides\n",
    "    test_hidden_block_stride = gen.make_gen_block(20, 20, kernel_size=4, stride=2)\n",
    "\n",
    "    test_final_noise = get_noise(num_test, gen.z_dim) * 20\n",
    "    test_final_block = gen.make_gen_block(10, 20, final_layer=True)\n",
    "    test_final_uns_noise = gen.unsqueeze_noise(test_final_noise)\n",
    "    final_output = test_final_block(test_final_uns_noise)\n",
    "    # print(final_output.shape)\n",
    "    # Test the whole thing:\n",
    "    test_gen_noise = get_noise(num_test, gen.z_dim)\n",
    "    test_uns_gen_noise = gen.unsqueeze_noise(test_gen_noise)\n",
    "    gen_output = gen(test_uns_gen_noise)\n",
    "\n",
    "    assert tuple(hidden_output.shape) == (num_test, 20, 4, 4)\n",
    "    assert hidden_output.max() > 1\n",
    "    assert hidden_output.min() == 0\n",
    "    assert hidden_output.std() > 0.2\n",
    "    assert hidden_output.std() < 1\n",
    "    assert hidden_output.std() > 0.5\n",
    "\n",
    "    assert tuple(test_hidden_block_stride(hidden_output).shape) == (num_test, 20, 10, 10)\n",
    "    assert final_output.max().item() == 1\n",
    "    assert final_output.min().item() == -1\n",
    "    \n",
    "    assert tuple(gen_output.shape) == (num_test, 1, 28, 28)\n",
    "    assert gen_output.std() > 0.5\n",
    "    assert gen_output.std() < 0.8\n",
    "    print(\"Success!\")\n",
    "\n",
    "test_generator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN Discriminator\n",
    "\n",
    "For the discriminator, you can wrap each `nn.Conv2d` with `nn.utils.spectral_norm`. In the backend, this introduces parameters for $\\tilde{u}$ and $\\tilde{v}$ in addition to $W$ so that the $W_{SN}$ can be computed as $\\tilde{u}^\\top W\\tilde{v}$ in runtime.\n",
    "\n",
    "Pytorch also provides a `nn.utils.remove_spectral_norm` function, which collapses the 3 separate parameters into a single explicit $\\overline{W}_{SN} := \\tilde{u}^\\top W\\tilde{v}$. You should only apply this to your convolutional layers during inference to improve runtime speed.\n",
    "\n",
    "It is important note that spectral norm does not eliminate the need for batch norm. Spectral norm affects the weights of each layer, while batch norm affects the activations of each layer. You can see both in a discriminator architecture, but you can also see just one of them. Hope this is something you have fun experimenting with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, im_chan = 1, hidden_dim=16):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            self.make_disc_block(im_chan, hidden_dim),\n",
    "            self.make_disc_block(hidden_dim, hidden_dim*2),\n",
    "            self.make_disc_block(hidden_dim*2, 1, final_layer=True)\n",
    "        )\n",
    "    \n",
    "    def make_disc_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.utils.spectral_norm(\n",
    "                    nn.Conv2d(input_channels, output_channels, kernel_size, stride)\n",
    "                ),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            )\n",
    "        else: return nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size, stride)\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        disc_pred = self.disc(image)\n",
    "        return disc_pred.view(len(disc_pred), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SN-DCGAN\n",
    "\n",
    "You can now put everything together and train a spectrally normalized DCGAN! Here are all your parameters for initialization and optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "n_epochs = 50\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "# A learning rate of 0.0002 works well on DCGAN\n",
    "lr = 0.0002\n",
    "\n",
    "# These parameters control the optimizer's momentum, which you can read more about here:\n",
    "# https://distill.pub/2017/momentum/ but you don’t need to worry about it for this course\n",
    "beta_1 = 0.5 \n",
    "beta_2 = 0.999\n",
    "device = 'cpu'\n",
    "\n",
    "# We tranform our image values to be between -1 and 1 (the range of the tanh activation)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    MNIST(\".\", download=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "\n",
    "disc = Discriminator()\n",
    "disc_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m,nn.Conv2d) or isinstance(m,nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m,nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "gen = gen.apply(weights_init)\n",
    "disc = disc.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 40/469 [00:17<03:07,  2.29it/s]"
     ]
    }
   ],
   "source": [
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for real, _ in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "        disc_opt.zero_grad()\n",
    "\n",
    "        fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake = gen(fake_noise)\n",
    "\n",
    "        disc_fake_pred = disc(fake.detach())\n",
    "        disc_real_pred = disc(real)\n",
    "\n",
    "        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
    "\n",
    "        disc_loss = (disc_fake_loss + disc_real_loss)/2\n",
    "        # print(disc_loss)\n",
    "        mean_discriminator_loss += disc_loss.item()/display_step\n",
    "\n",
    "        disc_loss.backward(retain_graph= True)\n",
    "        disc_opt.step()\n",
    "\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake_2 = gen(fake_noise_2)\n",
    "        disc_fake_pred = disc(fake_2)\n",
    "        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "\n",
    "        mean_generator_loss += gen_loss.item()/display_step\n",
    "\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        ## Visualization code ##\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "            show_tensor_images(fake)\n",
    "            show_tensor_images(real)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25bd78f2216d62d7966c8ec7b6ee5456516025b4c9c9f70a40d84f0a6fbf7185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
