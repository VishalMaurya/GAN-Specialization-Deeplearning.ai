{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "In this notebook, you're going to create another GAN using the MNIST dataset. You will implement a Deep Convolutional GAN (DCGAN), a very successful and influential GAN model developed in 2015.\n",
    "\n",
    "*Note: [here](https://arxiv.org/pdf/1511.06434v1.pdf) is the paper if you are interested! It might look dense now, but soon you'll be able to understand many parts of it :)*\n",
    "\n",
    "### Learning Objectives\n",
    "1.   Get hands-on experience making a widely used GAN: Deep Convolutional GAN (DCGAN).\n",
    "2.   Train a powerful generative model.\n",
    "\n",
    "\n",
    "![Generator architecture](dcgan-gen.png)\n",
    "\n",
    "Figure: Architectural drawing of a generator from DCGAN from [Radford et al (2016)](https://arxiv.org/pdf/1511.06434v1.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "#### DCGAN\n",
    "Here are the main features of DCGAN (don't worry about memorizing these, you will be guided through the implementation!): \n",
    "\n",
    "<!-- ```\n",
    "Architecture guidelines for stable Deep Convolutional GANs\n",
    "• Replace any pooling layers with strided convolutions (discriminator) and fractional-strided\n",
    "convolutions (generator).\n",
    "• Use BatchNorm in both the generator and the discriminator.\n",
    "• Remove fully connected hidden layers for deeper architectures.\n",
    "• Use ReLU activation in generator for all layers except for the output, which uses Tanh.\n",
    "• Use LeakyReLU activation in the discriminator for all layers.\n",
    "``` -->\n",
    "\n",
    "\n",
    "*   Use convolutions without any pooling layers\n",
    "*   Use batchnorm in both the generator and the discriminator\n",
    "*   Don't use fully connected hidden layers\n",
    "*   Use ReLU activation in the generator for all layers except for the output, which uses a Tanh activation.\n",
    "*   Use LeakyReLU activation in the discriminator for all layers except for the output, which does not use an activation\n",
    "\n",
    "You will begin by importing some useful packages and data that will help you create your GAN. You are also provided a visualizer function to help see the images your GAN will create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0) # Set for testing purposes, please do not change!\n",
    "\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    image_tensor = (image_tensor + 1)/2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create generator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, im_chan = 1, hidden_dim = 64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.gen = nn.Sequential(\n",
    "            self.make_gen_block(z_dim, hidden_dim * 4),\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim),\n",
    "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "            \n",
    "    def unsqueeze_noise(self, noise):\n",
    "        return noise.view(len(noise), self.z_dim, 1, 1)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        x = self.unsqueeze_noise(noise)\n",
    "        return self.gen(x)\n",
    "\n",
    "def get_noise(n_sample, z_dim, device='cpu'):\n",
    "    return torch.randn(n_sample, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# unit test for generator class\n",
    "def test_generator(num_test=100):\n",
    "    gen = Generator()\n",
    "\n",
    "    test_hidden_noise = get_noise(num_test, gen.z_dim) # (100, 10)\n",
    "    test_hidden_block = gen.make_gen_block(10, 20, 4, 1)\n",
    "    test_uns_noise = gen.unsqueeze_noise(test_hidden_noise) # (100, 10, 1, 1)\n",
    "    hidden_output = test_hidden_block(test_uns_noise) # (100, 20, 4, 4)\n",
    "\n",
    "    # Check that it works with other strides\n",
    "    test_hidden_block_stride = gen.make_gen_block(20, 20, kernel_size=4, stride=2)\n",
    "\n",
    "    test_final_noise = get_noise(num_test, gen.z_dim) * 20\n",
    "    test_final_block = gen.make_gen_block(10, 20, final_layer=True)\n",
    "    test_final_uns_noise = gen.unsqueeze_noise(test_final_noise)\n",
    "    final_output = test_final_block(test_final_uns_noise)\n",
    "    # print(final_output.shape)\n",
    "    # Test the whole thing:\n",
    "    test_gen_noise = get_noise(num_test, gen.z_dim)\n",
    "    test_uns_gen_noise = gen.unsqueeze_noise(test_gen_noise)\n",
    "    gen_output = gen(test_uns_gen_noise)\n",
    "\n",
    "    assert tuple(hidden_output.shape) == (num_test, 20, 4, 4)\n",
    "    assert hidden_output.max() > 1\n",
    "    assert hidden_output.min() == 0\n",
    "    assert hidden_output.std() > 0.2\n",
    "    assert hidden_output.std() < 1\n",
    "    assert hidden_output.std() > 0.5\n",
    "\n",
    "    assert tuple(test_hidden_block_stride(hidden_output).shape) == (num_test, 20, 10, 10)\n",
    "    assert final_output.max().item() == 1\n",
    "    assert final_output.min().item() == -1\n",
    "    \n",
    "    assert tuple(gen_output.shape) == (num_test, 1, 28, 28)\n",
    "    assert gen_output.std() > 0.5\n",
    "    assert gen_output.std() < 0.8\n",
    "    print(\"Success!\")\n",
    "\n",
    "test_generator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create discriminator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, im_chan = 1, hidden_dim=16):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            self.make_disc_block(im_chan, hidden_dim),\n",
    "            self.make_disc_block(hidden_dim, hidden_dim * 2),\n",
    "            self.make_disc_block(hidden_dim * 2, 1, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_disc_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.LeakyReLU(0.2, inplace = True)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride)\n",
    "            )\n",
    "\n",
    "    def forward(self, image):\n",
    "        disc_pred = self.disc(image)\n",
    "        return disc_pred.view(len(disc_pred), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# unit test for discriminator class\n",
    "def test_discriminator(num_test=100):\n",
    "    gen = Generator(z_dim=10)\n",
    "    disc = Discriminator()\n",
    "    test_images = gen(get_noise(num_test, gen.z_dim))\n",
    "\n",
    "    test_hidden_block = disc.make_disc_block(1, 5, kernel_size=6, stride=3)\n",
    "    hidden_output = test_hidden_block(test_images)\n",
    "\n",
    "    test_final_block = disc.make_disc_block(1, 10, kernel_size=2, stride=5, final_layer=True)\n",
    "    final_output = test_final_block(test_images)\n",
    "\n",
    "    disc_output = disc(test_images)\n",
    "\n",
    "    assert tuple(hidden_output.shape) == (num_test, 5, 8, 8)\n",
    "    # Because of the LeakyReLU slope\n",
    "    assert -hidden_output.min() / hidden_output.max() > 0.15\n",
    "    assert -hidden_output.min() / hidden_output.max() < 0.25\n",
    "    assert hidden_output.std() > 0.5\n",
    "    assert hidden_output.std() < 1\n",
    "\n",
    "    # Test the final block\n",
    "\n",
    "    assert tuple(final_output.shape) == (num_test, 10, 6, 6)\n",
    "    assert final_output.max() > 1.0\n",
    "    assert final_output.min() < -1.0\n",
    "    assert final_output.std() > 0.3\n",
    "    assert final_output.std() < 0.6\n",
    "\n",
    "    # Test the whole thing:\n",
    "\n",
    "    assert tuple(disc_output.shape) == (num_test, 1)\n",
    "    assert disc_output.std() > 0.25\n",
    "    assert disc_output.std() < 0.5\n",
    "    print(\"Success!\")\n",
    "\n",
    "test_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Now you can put it all together!\n",
    "Remember that these are your parameters:\n",
    "  *   criterion: the loss function\n",
    "  *   n_epochs: the number of times you iterate through the entire dataset when training\n",
    "  *   z_dim: the dimension of the noise vector\n",
    "  *   display_step: how often to display/visualize the images\n",
    "  *   batch_size: the number of images per forward/backward pass\n",
    "  *   lr: the learning rate\n",
    "  *   beta_1, beta_2: the momentum term\n",
    "  *   device: the device type\n",
    "\n",
    "<!-- In addition, be warned that **this runs very slowly on the default CPU**. One way to run this more quickly is to download the .ipynb and upload it to Google Drive, then open it with Google Colab, click on `Runtime -> Change runtime type` and set hardware accelerator to GPU and replace\n",
    "`device = \"cpu\"`\n",
    "with\n",
    "`device = \"cuda\"`. The code should then run without any more changes, over 1,000 times faster.  -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "# A learning rate of 0.0002 works well on DCGAN\n",
    "lr = 0.0002\n",
    "\n",
    "# These parameters control the optimizer's momentum, which you can read more about here:\n",
    "# https://distill.pub/2017/momentum/ but you don’t need to worry about it for this course!\n",
    "beta_1 = 0.5 \n",
    "beta_2 = 0.999\n",
    "device = 'cpu'\n",
    "\n",
    "# You can tranform the image values to be between -1 and 1 (the range of the tanh activation)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 6790656.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 25268188.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 2525617.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 7055751.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataloader = DataLoader(\n",
    "    MNIST('.', download=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr, betas = (beta_1, beta_2))\n",
    "\n",
    "disc = Discriminator().to(device)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr, betas = (beta_1, beta_2))\n",
    "\n",
    "# You initialize the weights to the normal distribution\n",
    "# with mean 0 and standard deviation 0.02\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "gen = gen.apply(weights_init)\n",
    "disc = disc.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 14/469 [00:07<03:55,  1.93it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [38], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m gen_loss \u001b[38;5;241m=\u001b[39m criterion(disc_fake_pred, torch\u001b[38;5;241m.\u001b[39mones_like(disc_fake_pred))\n\u001b[1;32m     33\u001b[0m mean_generator_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m gen_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39mdisplay_step\n\u001b[0;32m---> 34\u001b[0m \u001b[43mgen_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m gen_opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m## Visualization code ##\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loops\n",
    "n_epochs = 50\n",
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for real, _ in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "\n",
    "        fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake = gen(fake_noise)\n",
    "\n",
    "        disc_opt.zero_grad()\n",
    "        disc_fake_pred = disc(fake.detach())\n",
    "        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "\n",
    "        disc_real_pred = disc(real)\n",
    "        disc_real_loss = criterion(disc_real_pred, torch.zeros_like(disc_real_pred))\n",
    "        disc_loss = (disc_real_loss + disc_fake_loss)/2\n",
    "\n",
    "        mean_discriminator_loss += disc_loss.item()/display_step\n",
    "        disc_loss.backward(retain_graph= True)\n",
    "        disc_opt.step()\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake_2 = gen(fake_noise_2)\n",
    "        disc_fake_pred = disc(fake_2)\n",
    "        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "        \n",
    "        mean_generator_loss += gen_loss.item()/display_step\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        ## Visualization code ##\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "            show_tensor_images(fake)\n",
    "            show_tensor_images(real)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25bd78f2216d62d7966c8ec7b6ee5456516025b4c9c9f70a40d84f0a6fbf7185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
